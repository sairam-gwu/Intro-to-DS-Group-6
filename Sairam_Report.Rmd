---
title: "Video Game Sales and Performance Analysis"
author: "Sairam Venkatachalam"
date: "`r Sys.Date()`"
output:  
    rmdformats::readthedown:
      toc_float: true
      toc_depth: 3
      number_sections: true
      code_folding: hide
      
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r init, include=F}
# The package "ezids" (EZ Intro to Data Science) includes some helper functions we developed for the course. 
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
# You will need to install it (once) from GitHub.
# library(devtools)
# devtools::install_github("physicsland/ezids")
# Then load the package in your R session.
library(ezids)
library(ggplot2)
library(dplyr)
```


# 1. Introduction


## 1.1 Project Topic

The central focus of this project revolves around the comprehensive examination of video game sales and performance, delving into their dynamics, trends, and underlying factors to uncover valuable insights. Being avid video game enthusiasts, our team is looking to deep dive into the history of video game sales in order to find answers to our research questions

## 1.2 Data Source

The dataset used for this report was sourced through web scraping, specifically from Metacritic. It is important to note that certain observations are missing, as Metacritic covers only a subset of the gaming platforms. As a result, some games may not have complete information for all the variables. However, the dataset contains approximately 6,900 complete cases.

The dataset includes the following fields:

* Name
* Platform
* Year_of_Release
* Genre
* Publisher
* NA_Sales
* EU_Sales
* JP_Sales
* Other_Sales
* Global_Sales
* Critic_score (an aggregate score by Metacritic staff)
* Critic_count (the number of critics used for the Critic_score)
* User_score (score by Metacritic's subscribers)
* User_count (the number of users who provided the user_score)
* Developer (the party responsible for creating the game)
* Rating (ESRB ratings)


## 1.3 Project objectives and research questions

We will commence our analysis by conducting Exploratory Data Analysis on the dataset to unveil intriguing trends and patterns within the data.

After the completion of EDA, we wish to find answers to the following research questions:

* What proportion of shooter genre video games features a user score exceeding 8.0?
* What are the average user scores for games developed by Nintendo, and how do they compare with those from other game developers? Are these differences statistically significant?
* What is the trend in Global Sales over the years, and how has the recency of platforms influenced their popularity?
* Is there a statistically meaningful difference in mean sales between games with a rating of 7.5 or higher and those with a rating below 7.5? Can we identify a critical score associated with increased sales?



```{r}
games<-read.csv('Video games sales.csv')


```

# 2. Data Preprocessing

## 2.1 Structure of the dataset

The dataset that we have used contains information on the following attributes:

* Name
* Platform
* Year_of_Release
* Genre
* Publisher
* NA_Sales
* EU_Sales
* JP_Sales
* Other_Sales
* Global_Sales
* Critic_score (an aggregate score by Metacritic staff)
* Critic_count (the number of critics used for the Critic_score)
* User_score (score by Metacritic's subscribers)
* User_count (the number of users who provided the user_score)
* Developer (the party responsible for creating the game)
* Rating (ESRB ratings)


## 2.2 Data Cleaning

### Missing Observations

Despite the extensive number of variables present and the amount of rows in our dataset, there were a few limitations which required data cleaning :

* The dataset was aquired using web-scraping, leading to a few errors and ommisions in the data, these needed to be removed
* Some platforms had limited coverage on metacritic, leading to missing values in their user scores, critic scores or their sales

Before deciding on whether to remove the missing observations, we wanted to analyze their occurence based on the platform type

```{r}


plat_na= games %>%
  group_by(Platform) %>%
  summarize(NAs_in_User_Score = sum(is.na(User_Score)))


result <- games %>%
  group_by(Platform) %>%
  summarise(
    NA_Count = sum(is.na(User_Score)),
    Total_Count = n(),
    NA_Rate = NA_Count / Total_Count
  )


result$Platform <- reorder(result$Platform, -result$NA_Rate) 

ggplot(result, aes(x = Platform, y = NA_Rate)) +
  geom_bar(stat = "identity", fill = "#A5D8DD") +
  labs(title = "NA Rate by Platform", x = "Platform", y = "NA Rate") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))




```
As we can see there is a clear capture issue for certain platforms, while other more poplar platforms like PC and Xbox 360 have an NA Rate of less than 25%.

Hence, replacing the missing observations with an average value for the scores or sales would not make sense as it would distort the underlying platform specific behavior. Therefore, we decided to drop these observations


```{r}
games<-na.omit(games)
games$Rating <- ifelse(games$Rating== "", NA,games$Rating )
games<-subset(games,games$Rating!="NA")
games<-subset(games,games$Year_of_Release!="N/A")
```


### Outlier Handling

We identified outliers in the Global Sales data with significantly higher sales figures compared to most of the dataset.
As our analysis focused on comparing the means of different groups, the presence of these outliers could affect our results
```{r}



outlierKD2(games,Global_Sales,rm=FALSE,hist=TRUE,boxplt=TRUE,qqplt=TRUE)
```

As shown, the data with the inclusion the outliers, exhibits a substantial right-skew in both the histogram and boxplot, potentially affecting the validity of our statistical analyses.
By removing these outliers, the data became more normally distributed; although some right-skewness remains due to the inherent concentration of sales values near low values.



# 4. Research Questions


```{r}

games_final= outlierKD2(games,Global_Sales,rm=TRUE,hist=FALSE)
games_final<-na.omit(games_final)

```

## Research Question 1: 

**What proportion of all 'Shooter' Games have a User Score of >=8.0**

The idea of this research question was to get a sense of the proportion or percentage of games in the genre of 'Shooter' which had a high user rating which we defined at 8.0 or more. This was done in the following steps:

* First, we calculate the point estimate for the proportion from our sample
* Second, we calculate the standard error for out sample distribution. We use the t distribution as we don't know the standard deviation of the overall population
* Third, we calculate the critical t score that captures the 95% confidence interval for the proportion
* Finally, we calculate the upper and lower bounds using the point estimate and standard errors

```{r}
#----------------------------------------------------------------------------------------------------------------
# SMART Q - Confidence interval for Shooter game ratings

subset_data <- subset(games_final,games_final$Genre == 'Shooter' & games_final$User_Score >= 8.0)
shooter_data <- subset(games_final,games_final$Genre == 'Shooter')


sample_proportion <- nrow(subset_data) / nrow(shooter_data)

confidence_level <- 0.95

standard_error <- sqrt((sample_proportion * (1 - sample_proportion)) / nrow(shooter_data))

df <- nrow(shooter_data) - 1  # Degrees of freedom
t_critical <- qt(1 - (1 - confidence_level) / 2, df)  # t-critical value
margin_of_error <- t_critical * standard_error

# Calculate the confidence interval
lower_bound <- sample_proportion - margin_of_error
upper_bound <- sample_proportion + margin_of_error

# Print the results
cat("Sample Proportion:", sample_proportion, "\n")
cat("95% Confidence Interval :", lower_bound, "to", upper_bound, "\n")

x <- seq(sample_proportion - 4 * standard_error, sample_proportion + 4 * standard_error, length = 1000)


y <- dt((x - sample_proportion) / standard_error, df) 

# Create a data frame for plotting
plot_data <- data.frame(x = x, y = y)



ggplot(plot_data, aes(x = x, y = y)) +
  geom_line() +
  geom_vline(xintercept = c(lower_bound, upper_bound), color = "blue", linetype = "dashed", size = 1) +
  geom_ribbon(data = plot_data[plot_data$x >= lower_bound & plot_data$x <= upper_bound, ], aes(x = x, ymin = 0, ymax = y), fill = "pink", alpha = 0.5) +
  labs(
    title = "Sample Distribution for the propotion of game in the Shooter Genre with a rating >=8.0",
    x = "Proportion of Shooter Games with User Score > 8.0",
    y = "Probability Density"
  )+
  theme_minimal()

```

As shown, the sample proportion is around ```r sample_proportion``` which implies that 31.6% of 'Shooter' games in our dataset had a user rating of >=8.0

The confidence The 95% confidence interval for this proportion falls between 0.283 to 0.350 . This indicates that the true proportion of highly-rated shooter games likely lies within this range

Interestingly, the proportion of of non-shooter games is around 0.337 which is higher than shooter games.

## Research Question 2 : 

**What are the average user scores for games developed by Nintendo, and how do they compare to other companies? Are these differences statistically significant?**

The objective of this research question was to look at games developed by the developer giant Nintendo, to determine is they did better on average compares to non-nintendo games, specifically in terms of their user scores and critic scores.

We define the Hypotheses as follows:

* Null Hypothesis : There is no difference between the mean scores of games developed by Nintendo and others
* Alternate Hypothesis : There is a non-zero difference between the mean scores of games developed by Nintendo and others

```{r}
#------------------------------------------------------------------------------------------------------------------
# SMART Q - Nintendo vs Non- Nintendo


dev_nintendo=subset(games_final,games_final$Developer=='Nintendo')

dev_others=subset(games_final,games_final$Developer!='Nintendo')

#USer scores

t_test_nintendo <- t.test(dev_nintendo$User_Score,dev_others$User_Score,var.equal = FALSE,conf.level=0.99) 

t_test_nintendo

#Critic scores

t_test_nintendo <- t.test(dev_nintendo$Critic_Score,dev_others$Critic_Score,var.equal = FALSE,conf.level=0.99) 

t_test_nintendo


```

The results of our 2 sample t-tests give us enough to reject the null hypothesis in both cases. Nintendo performs much better compared to other developers, having on average a user score of **7.94** compared to **7.13** and critic score of **77.16** compared to **68.95**

```{r}

#--- Visually showing results


ggplot(games_final, aes(x = ifelse(grepl("Nintendo", games_final$Developer), "Nintendo", "Other"), y = User_Score, color = ifelse(grepl("Nintendo", games_final$Developer), "Nintendo", "Other"))) +
  geom_point() +
  labs(
    title = "User Score for Nintendo Games vs. Others",
    x = "Developer",
    y = "User Score"
  ) +
  scale_color_manual(name = "Developer", values = c("Nintendo" = "skyblue", "Other" = "orange")) +
  scale_x_discrete(labels = c("Nintendo" = "Nintendo", "Other" = "Other")) +
  theme_minimal() +
  theme(legend.position = "top")
#----



ggplot(games_final, aes(x = ifelse(grepl("Nintendo", games_final$Developer), "Nintendo", "Other"), y = Critic_Score, color = ifelse(grepl("Nintendo", games_final$Developer), "Nintendo", "Other"))) +
  geom_point() +
  labs(
    title = "Critic Score for Nintendo Games vs. Others",
    x = "Developer",
    y = "Critic Score"
  ) +
  scale_color_manual(name = "Developer", values = c("Nintendo" = "skyblue", "Other" = "orange")) +
  scale_x_discrete(labels = c("Nintendo" = "Nintendo", "Other" = "Other")) +
  theme_minimal() +
  theme(legend.position = "top")
#----

```

The scatter plots also clearly illustrate this difference. Nintendo benifits from producing a much lower number of badly rated games, and they maintain consistency. Perhaps, this is the main reason they have maintained their brand image over the years as an elite game developer


## Research Question 3 : 

**What is the Trend in global sales by year? How does this trend correlate to the usage of difference platforms?**


```{r}

#-----------------------------------------------------------------------------------------------------------------
# Smart Question 3 - Trend of Global sales by year of release

sales_by_year <- aggregate(Global_Sales ~ Year_of_Release, data = games_final, FUN = mean)

# Create a bar plot
ggplot(sales_by_year, aes(x = Year_of_Release, y = Global_Sales)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(
    title = "Average Global Sales by Year of Release",
    x = "Year of Release",
    y = "Average Global Sales"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



sales_by_year <- aggregate(Global_Sales ~ Year_of_Release, data = games_final, FUN = sum)

# Create a bar plot
ggplot(sales_by_year, aes(x = Year_of_Release, y = Global_Sales)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(
    title = "Total Global Sales by Year of Release",
    x = "Year of Release",
    y = "Total Global Sales"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

# 

* In the late 1990s and early 2000s, the video game industry witnessed an extraordinary surge in total global sales. This era marked a remarkable upswing in the popularity and sales of video games, redefining the entertainment landscape.

* Amidst this booming phase, PlayStation emerged as the predominant platform, playing a pivotal role in the industry's remarkable success. The introduction of the PlayStation 2 (PS2) made a substantial impact on the gaming market, solidifying Sony's position as a key player.

* However, post-2008, the industry experienced a gradual decline in global sales. This decline can be attributed, in part, to the global economic recession, which had ripple effects across various sectors. Furthermore, a noticeable shift in consumer preferences toward mobile gaming contributed to the evolving landscape of the industry. These changes prompted both players and industry leaders to adapt and innovate in response to emerging trends.



```{r}
max_platform <- games_final %>%
  group_by(Year_of_Release, Platform) %>%
  summarise(Total_Sales = sum(Global_Sales)) %>%
  top_n(1, Total_Sales)


ggplot(data = max_platform, aes(x = Year_of_Release, y = Total_Sales, fill = Platform)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Total Global Sales by Year for the best performing platform",
    x = "Year of Release",
    y = "Total Global Sales"
  )+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

* As the graph above shows, there is a clear trend in platform usage between different eras. The 90's saw mainstream usage of PS and PC.

* The 00's was the era of PS2. Most developers are publishers targeted the PS2 console for the release of their games due to its high popularity and affordable price among users 

* The release of the Wii created shockwaves in the market, with Wii sports being the game with the highest copies sold in history!

* Following the short dominance of Wii, The playstation made a comeback with PS3 which once again dominated for half a decade


## Research Question 4 : 

**Is there a statistically significant difference in mean sales for games with a rating of 7.5 or higher compared to those with a rating below 7.5? Can we determine a critical score that leads to higher sales?**

The primary goal of this research question is to assess the disparity in global sales between video games with a rating of 7.5 or higher and those with lower ratings.

Subsequently, We aim to determine a critical rating threshold at which the most substantial sales difference becomes evident.

The Hyoptheses are defined as follows :

* Null Hypothesis : There is no difference between the mean sales of both groups
* Altername Hypothesis : There is a non-zero difference between the mean sales of both groups

### Threshold score of 7.5

```{r}



#-----------------------------------------------------------------------------------------------------------------
# SMART Q - Threshold Rating


rating_above <- subset(games_final, games_final$User_Score >= 7.5)
rating_below <- subset(games_final, games_final$User_Score < 7.5)

# Calculate the sample means
mean_sales_above <- mean(rating_above$Global_Sales)
mean_sales_below <- mean(rating_below$Global_Sales)

# Calculate the difference in means
diff_means <- mean_sales_above - mean_sales_below

# Perform a t-test for the two groups with unequal variances
t_test_result <- t.test(rating_above$Global_Sales, rating_below$Global_Sales, var.equal = FALSE)

cat("Mean difference is:", diff_means, "\n")
cat("P-Value for the T-Test:", t_test_result$p.value, "\n")


ggplot(games_final, aes(x = User_Score, y = Global_Sales, color = User_Score >= 7.5)) +
  geom_point() +
  scale_color_manual(values = c("red", "green"), 
                     breaks = c(FALSE, TRUE), 
                     labels = c("< 7.5", ">= 7.5")) +
  labs(x = "User Score", y = "Global Sales (Millions)", title = "User Score vs. Global Sales") +
  guides(color = guide_legend(title = "User Score")) +
  theme_minimal()




```

As shown, the p value associated with the 2 sample t-test is low enough for us to reject the Null hypothesis

The difference in mean sales at the 7.5 rating threshold is 0.09 Million which is quite small. As the scatter plot illustrates, there is a lot of spread for games rated 7.5 or more, indicating a more multivariate complex relationship for the global sales.



### Iterating to find the critical score

```{r}
#-----------------------------------------------------------------------------------------------------------------

#Iterating to find threshold

thresholds <- numeric()
diff_means_values <- numeric()
p_values <- numeric()

best_rating_threshold <- NA
best_diff_means <- -Inf
best_p_value <- 1  # Initialize with a value above 0.05


for (rating_threshold in seq(4.0, 8.5, by = 0.1)) {
  # Subset data for games with user scores above and below the threshold
  rating_above <- subset(games_final, games_final$User_Score >= rating_threshold)
  rating_below <- subset(games_final, games_final$User_Score < rating_threshold)
  
  # Calculate the sample means
  mean_sales_above <- mean(rating_above$Global_Sales)
  mean_sales_below <- mean(rating_below$Global_Sales)
  
  # Calculate the difference in means
  diff_means <- mean_sales_above - mean_sales_below
  
  # Perform a t-test for the two groups with unequal variances
  t_test_result <- t.test(rating_above$Global_Sales, rating_below$Global_Sales, var.equal = FALSE)
  
  # Store the results in vectors
  thresholds <- c(thresholds, rating_threshold)
  diff_means_values <- c(diff_means_values, diff_means)
  p_values <- c(p_values, t_test_result$p.value)
  
  # Check if the result is better than the current best result
  if (diff_means > best_diff_means && t_test_result$p.value < 0.05) {
    best_diff_means <- diff_means
    best_p_value <- t_test_result$p.value
    best_rating_threshold <- rating_threshold
  }
}

# Print the best result
cat("Best rating split with the highest mean difference and p-value below 0.05 is:", best_rating_threshold, "\n")
cat("Mean Difference in Sales:", best_diff_means, "\n")
cat("P-Value for the T-Test:", best_p_value, "\n")

```

As shown, the user score of 4.1 produces the highest difference in mean global sales between both groups at 0.17 Million copies. The p value associated with the test is enough to reject the Null Hypothesis.

We can see a steady decline in the mean differences as the user score increases while always remaining positive. This indicates that the 2 variables are weakly correlated. When calculating the Pearson correlation coefficient, we get a 
value of 0.145

```{r}
#-- Visually showing the result
plot(
  thresholds, 
  diff_means_values, 
  type = "l", 
  col = "blue", 
  xlab = "Rating Threshold", 
  ylab = "Mean Difference in Sales",
  main = "Threshold vs. Mean Difference in Sales",
  xlim = c(3.8, 8),
  ylim = c(max(diff_means_values) * 0.5, max(diff_means_values) * 1.1)
)

# Label points with maximum mean difference
max_diff_idx <- which.max(diff_means_values)
text(
  thresholds[max_diff_idx], 
  diff_means_values[max_diff_idx], 
  labels = paste("Threshold:", thresholds[max_diff_idx], "\n Difference:", round(diff_means_values[max_diff_idx], 2)),
  pos = 3,
  col = "blue"
)







# Create a new plot for p-value vs. rating
par(mar = c(5, 5, 4, 5))  # Adjust margin for labels
plot(
  thresholds, 
  -log10(p_values), 
  type = "l", 
  col = "red", 
  xlab = "Rating Threshold", 
  ylab = "-log10(P-Value)",
  main = "User Rating vs. P-Value",
  xlim = c(4, 8),
  ylim = c(0, max(-log10(p_values)) + 2)
)

```

The p values are of the order of magnitude of -10 or lower indicating that the results are statistically significant across the board

```{r}
ggplot(games_final, aes(x = User_Score, y = Global_Sales, color = User_Score >= 4.1)) +
  geom_point() +
  scale_color_manual(values = c("red", "green"), 
                     breaks = c(FALSE, TRUE), 
                     labels = c("< 4.1", ">= 4.1")) +
  labs(x = "User Score", y = "Global Sales (Millions)", title = "User Score vs. Global Sales") +
  guides(color = guide_legend(title = "User Score")) +
  theme_minimal()


```

Once again, the scatter chart illustrates the complex relationship between user score and global sales. For lower values of user score such as 4.1, we can see clear trends and a positive correlation. However, this behavior becomes diluted for higher user scores

### Bonferroni Correction

The Bonferroni test is a multiple-comparison correction used when several dependent or independent statistical tests are being performed simultaneously. The reason is that while a given alpha value may be appropriate for each individual comparison, it is not appropriate for the set of all comparisons. We must check if the p value is less than alpha (0.05) divided by the number of tests performed.

In the case of our tests, we are testing multiple user scores to determine whether the differences in the mean sales between the groups is statistically significant. However, given our p values are of the order -10 and lower, adjusting alpha with the Bonferroni correction would still yield very statistically significant results